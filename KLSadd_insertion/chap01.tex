\documentclass[envcountchap,graybox]{svmono}

\addtolength{\textwidth}{1mm}

\usepackage{amsmath,amssymb}

\usepackage{amsfonts}
%\usepackage{breqn}
\usepackage{DLMFmath}
\usepackage{DRMFfcns}

\usepackage{mathptmx}
\usepackage{helvet}
\usepackage{courier}

\usepackage{makeidx}
\usepackage{graphicx}

\usepackage{multicol}
\usepackage[bottom]{footmisc}

\makeindex

\def\bibname{Bibliography}
\def\refname{Bibliography}

\def\theequation{\thesection.\arabic{equation}}

\smartqed

\let\corollary=\undefined
\spnewtheorem{corollary}[theorem]{Corollary}{\bfseries}{\itshape}

\newcounter{rom}

\newcommand{\hyp}[5]{\mbox{}_{#1}{F}_{#2}
\left(\genfrac{}{}{0pt}{}{#3}{#4}\,;\,#5\right)}

\newcommand{\qhyp}[5]{\mbox{}_{#1}{\phi}_{#2}
\left(\genfrac{}{}{0pt}{}{#3}{#4}\,;\,q,\,#5\right)}

\newcommand{\mathindent}{\hspace{7.5mm}}

\newcommand{\e}{\textrm{e}}

\renewcommand{\E}{\textrm{E}}

\renewcommand{\textfraction}{-1}

\renewcommand{\Gamma}{\varGamma}

\renewcommand{\leftlegendglue}{\hfil}

\settowidth{\tocchpnum}{14\enspace}
\settowidth{\tocsecnum}{14.30\enspace}
\settowidth{\tocsubsecnum}{14.12.1\enspace}

\makeatletter
\def\cleartoversopage{\clearpage\if@twoside\ifodd\c@page
         \hbox{}\newpage\if@twocolumn\hbox{}\newpage\fi
         \else\fi\fi}

\newcommand{\clearemptyversopage}{
        \clearpage{\pagestyle{empty}\cleartoversopage}}
\makeatother

\oddsidemargin -1.5cm
\topmargin -2.0cm
\textwidth 16.3cm
\textheight 25cm 

\begin{document}

\author{Roelof Koekoek\\[2.5mm]Peter A. Lesky\\[2.5mm]Ren\'e F. Swarttouw}
\title{Hypergeometric orthogonal polynomials and their\\$q$-analogues}
\subtitle{-- Monograph --}
\maketitle

\frontmatter

\pagenumbering{roman}

\large

\chapter{Definitions and miscellaneous formulas}
\label{Definitions}


\section{Orthogonal polynomials}\index{Orthogonal polynomials}
\par\setcounter{equation}{0}
\label{orthogonal polynomials}

A system of polynomials $\left\{p_n(x)\right\}_{n=0}^{\infty}$ with degree$[p_n(x)]=n$ for all
$n\in\{0,1,2,\ldots\}$ is called orthogonal on an interval $(a,b)$ with respect to the weight
function $w(x)\geq 0$ if
\begin{equation}
\label{orth1}
\int_a^bp_m(x)p_n(x)w(x)\,dx=0,\quad m\neq n,\quad m,n\in\{0,1,2,\ldots\}.
\end{equation}
Here $w(x)$ is continuous or piecewise continuous or integrable, and such that
\begin{equation}
0<\int_a^bx^{2n}w(x)\,dx<\infty
%  \constraint{ $n\in\{0,1,2,\ldots\}$ }
\end{equation}
More generally, $w(x)\,dx$ may be replaced in this definition by a positive measure
$d\alpha(x)$, where $\alpha(x)$ is a bounded nondecreasing function on $[a,b]\cap\mathbb{R}$
with an infinite number of points of increase, and such that
\begin{equation}
0<\int_a^bx^{2n}\,d\alpha(x)<\infty
%  \constraint{ $n\in\{0,1,2,\ldots\}$ }
\end{equation}
If this function $\alpha(x)$ is constant between its (countably many) jump points then we have
the situation of positive weights $w_x$ on a countable subset $X$ of $\mathbb{R}$. Then the
system $\{p_n(x)\}_{n=0}^{\infty}$ is orthogonal on $X$ with respect to these weights as follows:
\begin{equation}
\label{orth2}
\sum_{x\in X}p_m(x)p_n(x)w_x=0,\quad m\neq n,\quad m,n\in\{0,1,2,\ldots\}.
\end{equation}
The case of weights $w_x$ ($x\in X$) on a finite set $X$ of $N+1$ points yields orthogonality
for a finite system of polynomials $\{p_n(x)\}_{n=0}^N$:
\begin{equation}
\label{orth3}
\sum_{x\in X}p_m(x)p_n(x)w_x=0,\quad m\neq n,\quad m,n\in\{0,1,2,\ldots,N\}.
\end{equation}
The orthogonality relations (\ref{orth1}), (\ref{orth2}) or (\ref{orth3}) determine the
polynomials $\{p_n(x)\}_{n=0}^{\infty}$ up to constant factors, which may be fixed by a
suitable normalization. We set:
\begin{equation}
\label{norm1}
\sigma_n=\int_a^b\left\{p_n(x)\right\}^2w(x)\,dx,\quad n=0,1,2,\ldots,
\end{equation}
\begin{equation}
\label{norm2}
\sigma_n=\sum_{x\in X}\left\{p_n(x)\right\}^2w_x,\quad n=0,1,2,\ldots
\end{equation}
or
\begin{equation}
\label{norm3}
\sigma_n=\sum_{x\in X}\left\{p_n(x)\right\}^2w_x,\quad n=0,1,2,\ldots,N,
\end{equation}
respectively and
\begin{equation}
\label{polynomial}
p_n(x)=k_nx^n+\,\textrm{lower order terms},\quad n=0,1,2,\ldots.
\end{equation}
Then we have the following normalizations:

\begin{enumerate}\itemsep2.5mm
\item $\sigma_n=1$ for all $n=0,1,2,\ldots$. In that case the system of polynomials is called
orthonormal. If moreover $k_n>0$, for instance, then the polynomials are uniquely determined.
\item $k_n=1$ for all $n=0,1,2,\ldots$. In that case the system of polynomials is called
monic. Also in this case the polynomials are uniquely determined.
\end{enumerate}
Polynomials $\{p_n(x)\}_{n=0}^{\infty}$ with degree$[p_n(x)]=n$ for all $n\in\{0,1,2,\ldots\}$
which are orthogonal with respect to a (piecewise) continuous or integrable weight function
$w(x)$ as in (\ref{orth1}) are called continuous orthogonal polynomials.\\
Polynomials $\{p_n(x)\}_{n=0}^N$ with degree$[p_n(x)]=n$ for all $n\in\{0,1,2,\ldots,N\}$ and
possibly $N\rightarrow\infty$ which are orthogonal with respect to a countable subset $X$ of
$\mathbb{R}$ as in (\ref{orth2}) or (\ref{orth3}) are called discrete orthogonal polynomials.\\
By using the Kronecker delta, defined by
\begin{equation}
\label{Kronecker}
\,\delta_{mn}:=\left\{\begin{array}{ll}0, &m\neq n,\\[5mm]
1, & m=n,\end{array}\right.\quad m,n\in\{0,1,2,\ldots\},
\end{equation}
orthogonality relations can be written in the form
\begin{equation}
\label{orth4}
\int_a^bp_m(x)p_n(x)w(x)\,dx=\sigma_n\,\delta_{mn},\quad m,n\in\{0,1,2,\ldots\}
\end{equation}
or (with possibly $N\rightarrow\infty$)
\begin{equation}
\label{orth5}
\sum_{x\in X}p_m(x)p_n(x)w_x=\sigma_n\,\delta_{mn},\quad m,n\in\{0,1,2,\ldots,N\},
\end{equation}
respectively.

\section{The gamma and beta function}
\par\setcounter{equation}{0}
\label{gamma function}

For $\textrm{Re}\,z>0$ the gamma function can be defined by the
gamma integral $\EulerGamma@{z}$
\begin{equation}
\label{DefGamma}\index{Gamma function}
\Gamma(z):=\int_0^{\infty}t^{z-1}\e^{-t}\,dt,\quad\textrm{Re}\,z>0.
\end{equation}
This gamma function satisfies the well-known functional equation
\begin{equation}
\label{GammaFunctional}
\Gamma(z+1)=z\Gamma(z)
%  \constraint{ $\Gamma(1)=1$ }
\end{equation}
which shows that $\Gamma(n+1)=n!$ for $n\in\{0,1,2,\ldots\}$.
For non-integral values of $z$, the gamma function also satisfies the reflection formula
\begin{equation}
\label{GammaReflection}
\Gamma(z)\Gamma(1-z)=\frac{\pi}{\sin(\pi z)},\quad z\notin\mathbb{Z}.
\end{equation}
Hence we have $\Gamma(1/2)=\sqrt{\pi}$, which implies that
\begin{equation}
\label{IntExp}
\int_{-\infty}^{\infty}\e^{-x^2}\,dx=2\int_0^{\infty}\e^{-x^2}\,dx
=\int_0^{\infty}t^{-1/2}\e^{-t}\,dt=\Gamma(1/2)=\sqrt{\pi}.
\end{equation}
More general we have
\begin{equation}
\label{IntHermite}
\int_{-\infty}^{\infty}\e^{-\alpha^2x^2-2\beta x}\,dx
=\sqrt{\frac{\pi}{\alpha^2}}\,\e^{\beta^2/\alpha^2},
%  \constraint{ 
%    $\alpha,\beta\in\Real$ &
%    $\alpha\neq 0$ }
\end{equation}
Further we have Legendre's duplication formula
\begin{equation}
\label{GammaDuplication}
\Gamma(z)\Gamma(z+1/2)=2^{1-2z}\sqrt{\pi}\,\Gamma(2z)
%  \constraint{
%    $z\in\Complex$ &
%    $2z\neq 0,-1,-2,\ldots$ }
\end{equation}
and Stirling's asymptotic formula
\begin{equation}
\label{GammaAsymptotic}
\Gamma(z)\sim\sqrt{2\pi}\,z^{z-1/2}\e^{-z},\quad\textrm{Re}\,z\rightarrow\infty.
\end{equation}
For $z=x+iy$ with $x,y\in\mathbb{R}$ we also have
\begin{equation}
\label{GammaAsymptotic2}
\Gamma(x+iy)\sim\sqrt{2\pi}\,|y|^{x-1/2}\e^{-|y|\pi/2},\quad|y|\rightarrow\infty
\end{equation}
and for the ratio of two gamma functions we have the asymptotic
formula
\begin{equation}
\label{GammaAsymptotic3}
\frac{\Gamma(z+a)}{\Gamma(z+b)}\sim z^{a-b},\quad
%  \constraint{
%    $a,b\in\Complex$ & 
%    $|z|\rightarrow\infty$ }
\end{equation}

For $\textrm{Re}\,x>0$ and $\textrm{Re}\,y>0$ the beta function can be defined
by the integral
\begin{equation}
\label{DefBeta}\index{Beta function}
\textrm{B}(x,y):=\int_0^1t^{x-1}(1-t)^{y-1}\,dt
%  \constraint{
%    $\textrm{Re}\,x>0$ &
%    $\textrm{Re}\,y>0$ }
\end{equation}
The connection between the beta function and the gamma function is
given by the relation
\begin{equation}
\label{BetaGamma}
\textrm{B}(x,y)=\frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}
%  \constraint{
%    $\textrm{Re}\,x>0$ &
%    $\textrm{Re}\,y>0$ }
\end{equation}
There is another beta integral due to Cauchy, which can be written as
\begin{equation}
\label{Cauchy}
\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{dt}{(r+it)^{\rho}(s-it)^{\sigma}}
=\frac{(r+s)^{1-\rho-\sigma}\Gamma(\rho+\sigma-1)}{\Gamma(\rho)\Gamma(\sigma)}
\end{equation}
for $\textrm{Re}\,r>0$, $\textrm{Re}\,s>0$ and $\textrm{Re}(\rho+\sigma)>1$.

\section{The shifted factorial and binomial coefficients}
\par\setcounter{equation}{0}
\label{pochhammer symbol}

The shifted factorial -- or Pochhammer symbol -- is defined by
\begin{equation}
\label{Pochhammer}\index{Shifted factorial}
(a)_0:=1\quad\textrm{and}\quad (a)_k:=\prod_{n=1}^k(a+n-1)
%  \constraint{ $k=1,2,3,\ldots$ }
\end{equation}
This can be seen as a generalization of the factorial since
$$(1)_n=n!,\quad n=0,1,2,\ldots.$$

The binomial coefficient can be defined by
\begin{equation}
\label{binomialcoeff}\index{Binomial coefficient}
\binom{\alpha}{\beta}:=\frac{\Gamma(\alpha+1)}{\Gamma(\beta+1)\Gamma(\alpha-\beta+1)}.
\end{equation}
For integer values of the parameter $\beta$ we have
$$\binom{\alpha}{k}:=\frac{(-\alpha)_k}{k!}(-1)^k,\quad k=0,1,2,\ldots$$
and when the parameter $\alpha$ is an integer too, we have
\begin{equation}
\binom{n}{k}:=\frac{n!}{k!\,(n-k)!}
%  \constraint{
%    $k=0,1,2,\ldots,n$ &
%    $n=0,1,2,\ldots$ }
\end{equation}
The latter formula can be used to show that
$$\binom{2n}{n}=\frac{\left(\frac{1}{2}\right)_n}{n!}4^n,\quad n=0,1,2,\ldots.$$

\section{Hypergeometric functions}
\par\setcounter{equation}{0}
\label{hypergeometric functions}

The hypergeometric function $\mbox{}_rF_s$ is defined by the series
\begin{equation}
\label{DefHyp}\index{Hypergeometric function}
\hyp{r}{s}{a_1,\ldots,a_r}{b_1,\ldots,b_s}{z}:=
\sum\limits_{k=0}^{\infty}\frac{(a_1,\ldots,a_r)_k}{(b_1,\ldots,b_s)_k}
\frac{z^k}{k!},
\end{equation}
where
$$(a_1,\ldots,a_r)_k:=(a_1)_k\cdots(a_r)_k.$$
Of course, the parameters must be such that the denominator factors in the
terms of the series are never zero. When one of the numerator parameters
$a_j$ equals $-n$, where $n$ is a nonnegative integer, this hypergeometric
function is a polynomial in $z$. Otherwise the radius of convergence $\rho$ of
the hypergeometric series is given by
$$\rho=\left\{\begin{array}{ll}
\displaystyle \infty & \quad\textrm{if}\quad r < s+1\\[5mm]
\displaystyle 1 & \quad\textrm{if}\quad r = s+1\\[5mm]
\displaystyle 0 & \quad\textrm{if}\quad r > s+1.\end{array}\right.$$

A hypergeometric series of the form (\ref{DefHyp}) is called
balanced\index{Hypergeometric function!Balanced} or
Saalsch\"{u}tzian\index{Hypergeometric function!Saalsch\"{u}tzian}
if $r=s+1$, $z=1$ and $a_1+a_2+ \ldots +a_{s+1}+1=b_1+b_2+ \ldots +b_s$.

Many limit relations between hypergeometric orthogonal polynomials are based on the observations that
\begin{equation}
\label{hypsub}
\hyp{r}{s}{a_1,\ldots,a_{r-1},\mu}{b_1,\ldots,b_{s-1},\mu}{z}
=\hyp{r-1}{s-1}{a_1,\ldots,a_{r-1}}{b_1,\ldots,b_{s-1}}{z},
\end{equation}
\begin{equation}
\label{hyplim1}
\lim\limits_{\lambda\rightarrow\infty}
\hyp{r}{s}{a_1,\ldots,a_{r-1},\lambda a_r}{b_1,\ldots,b_s}{\frac{z}{\lambda}}
=\hyp{r-1}{s}{a_1,\ldots,a_{r-1}}{b_1,\ldots,b_s}{a_rz},
\end{equation}
\begin{equation}
\label{hyplim2}
\lim\limits_{\lambda\rightarrow\infty}
\hyp{r}{s}{a_1,\ldots,a_r}{b_1,\ldots,b_{s-1},\lambda b_s}{\lambda z}=
\hyp{r}{s-1}{a_1,\ldots,a_r}{b_1,\ldots,b_{s-1}}{\frac{z}{b_s}}
\end{equation}
and
\begin{equation}
\label{hyplim3}
\lim\limits_{\lambda\rightarrow\infty}
\hyp{r}{s}{a_1,\ldots,a_{r-1},\lambda a_r}{b_1,\ldots,b_{s-1},\lambda b_s}{z}
=\hyp{r-1}{s-1}{a_1,\ldots,a_{r-1}}{b_1,\ldots,b_{s-1}}{\frac{a_rz}{b_s}}.
\end{equation}

Mostly, the left-hand side of (\ref{hypsub}) occurs as a limit case where some numerator
parameter and some denominator parameter tend to the same value.

All families of discrete orthogonal polynomials $\{P_n(x)\}_{n=0}^N$ are
defined for $n=0,1,2,\ldots,N$, where $N$ is a positive integer. In these
cases something like (\ref{hypsub}) occurs in the hypergeometric representation when $n=N$.
In these cases we have to be aware of the fact that we still have a polynomial (in that case of
degree $N$). For instance, if we take $n=N$ in the hypergeometric representation (\ref{DefHahn})
of the Hahn polynomials, we have
$$Q_N(x;\alpha,\beta,N)=\sum_{k=0}^N\frac{(N+\alpha+\beta+1)_k(-x)_k}{(\alpha+1)_kk!}.$$
So these cases must be understood by continuity.

In cases of discrete orthogonal polynomials, we need a special notation for
some of the generating functions. We define
$$\left[f(t)\right]_N:=\sum_{k=0}^N\frac{f^{(k)}(0)}{k!}t^k,$$
for every function $f$ for which $f^{(k)}(0)$, $k=0,1,2,\ldots,N$ exists. As
an example of the use of this $N$th partial sum of a power series in $t$ we
remark that the generating function (\ref{GenKrawtchouk2}) for the
Krawtchouk polynomials must be understood as follows: the $N$th partial sum
of
$$\e^t\,\hyp{1}{1}{-x}{-N}{-\frac{t}{p}}=
\sum_{k=0}^{\infty}\frac{t^k}{k!}\sum_{m=0}^x\frac{(-x)_m}{(-N)_mm!}
\left(-\frac{t}{p}\right)^m$$
equals
$$\sum_{n=0}^N\frac{K_n(x;p,N)}{n!}t^n$$
for $x=0,1,2,\ldots,N$.

The classical exponential function $\e^z$ and the trigonometric functions
$\cos z$ and $\sin z$ can be expressed in terms of hypergeometric functions
as
\begin{equation}
\label{exp}
\e^z=\hyp{0}{0}{-}{-}{z},
\end{equation}
\begin{equation}
\label{cos}
\cos z=\hyp{0}{1}{-}{\frac{1}{2}}{-\frac{z^2}{4}}
\end{equation}
and
\begin{equation}
\label{sin}
\sin z=z\,\hyp{0}{1}{-}{\frac{3}{2}}{-\frac{z^2}{4}}.
\end{equation}

Further we have the well-known Bessel function of the first kind $J_{\nu}(z)$, which can be
defined by
\begin{equation}
\label{Bessel}\index{Bessel function}
J_{\nu}(z):=\frac{\left(\frac{1}{2}z\right)^{\nu}}{\Gamma(\nu+1)}\,
\hyp{0}{1}{-}{\nu+1}{-\frac{z^2}{4}}.
\end{equation}

\section{The binomial theorem and other summation formulas}
\par\setcounter{equation}{0}
\label{summation formulas}

One of the most important summation formulas for hypergeometric series is
given by the binomial theorem:
\begin{equation}
\label{binomial}\index{Binomial theorem}\index{Summation formula!Binomial theorem}
\hyp{1}{0}{a}{-}{z}=\sum_{n=0}^{\infty}\frac{(a)_n}{n!}z^n=(1-z)^{-a},
%  \constraint{ $\quad |z|<1$ }
\end{equation}
which is a generalization of Newton's binomium
\begin{equation}
\label{Newton}
\hyp{1}{0}{-n}{-}{z}=\sum_{k=0}^n\frac{(-n)_k}{k!}z^k
=\sum_{k=0}^n\binom{n}{k}(-z)^k=(1-z)^n,\quad n=0,1,2,\ldots.
\end{equation}

We also have Gauss's summation formula
\begin{equation}
\label{Gauss}\index{Gauss summation formula}\index{Summation formula!Gauss}
\hyp{2}{1}{a,b}{c}{1}=
\frac{\Gamma(c)\Gamma(c-a-b)}{\Gamma(c-a)\Gamma(c-b)}
%  \constraint{ $\textrm{Re}(c-a-b)>0$ }
\end{equation}
and the Vandermonde or Chu-Vandermonde summation formula
\begin{equation}
\label{ChuVandermonde}
\index{Vandermonde summation formula}\index{Summation formula!Vandermonde}
\index{Chu-Vandermonde summation formula}\index{Summation formula!Chu-Vandermonde}
\hyp{2}{1}{-n,b}{c}{1}=\frac{(c-b)_n}{(c)_n},\quad n=0,1,2,\ldots.
\end{equation}

On the next level we have the summation formula
\begin{equation}
\label{PfaffSaalschutz}
\index{Saalsch\"{u}tz summation formula}\index{Summation formula!Saalsch\"{u}tz}
\index{Pfaff-Saalsch\"{u}tz summation formula}\index{Summation formula!Pfaff-Saalsch\"{u}tz}
\hyp{3}{2}{-n,a,b}{c,1+a+b-c-n}{1}=\frac{(c-a)_n(c-b)_n}{(c)_n(c-a-b)_n},
\quad n=0,1,2,\ldots,
\end{equation}
which is called the Saalsch\"{u}tz or Pfaff-Saalsch\"{u}tz summation formula.

For a very-well-poised ${}_5F_4$ we have the summation formula
\begin{eqnarray}
\label{wellpoised}\index{Summation formula!for a very-well-poised ${}_5F_4$}
& &\hyp{5}{4}{1+a/2,a,b,c,d}{a/2,1+a-b,1+a-c,1+a-d}{1}\nonumber\\
& &{}=\frac{\Gamma(1+a-b)\Gamma(1+a-c)\Gamma(1+a-d)\Gamma(1+a-b-c-d)}
{\Gamma(1+a)\Gamma(1+a-b-c)\Gamma(1+a-b-d)\Gamma(1+a-c-d)}.
\end{eqnarray}
The limit case $d\rightarrow -\infty$ leads to
\begin{equation}
\label{wellpoisedlimit}
\hyp{4}{3}{1+a/2,a,b,c}{a/2,1+a-b,1+a-c}{-1}
=\frac{\Gamma(1+a-b)\Gamma(1+a-c)}{\Gamma(1+a)\Gamma(1+a-b-c)}.
\end{equation}

Finally, we mention Dougall's bilateral sum
\begin{equation}
\label{Dougall1}\index{Dougall's bilateral sum}\index{Summation formula!Dougall}
\sum_{n=-\infty}^{\infty}\frac{\Gamma(n+a)\Gamma(n+b)}{\Gamma(n+c)\Gamma(n+d)}
=\frac{\Gamma(a)\Gamma(1-a)\Gamma(b)\Gamma(1-b)\Gamma(c+d-a-b-1)}
{\Gamma(c-a)\Gamma(d-a)\Gamma(c-b)\Gamma(d-b)},
\end{equation}
which holds for $\textrm{Re}(a+b)+1<\textrm{Re}(c+d)$.\\
By using
$$\Gamma(n+a)\Gamma(n+b)=\frac{\Gamma(a)\Gamma(1-a)\Gamma(b)\Gamma(1-b)}
{\Gamma(1-a-n)\Gamma(1-b-n)},\quad n\in\mathbb{Z},$$
Dougall's bilateral sum can also be written in the form
\begin{eqnarray}
\label{Dougall2}
& &\sum_{n=-\infty}^{\infty}\frac{1}{\Gamma(n+c)\Gamma(n+d)\Gamma(1-a-n)\Gamma(1-b-n)}\nonumber\\
& &{}=\frac{\Gamma(c+d-a-b-1)}{\Gamma(c-a)\Gamma(d-a)\Gamma(c-b)\Gamma(d-b)}
\end{eqnarray}
for $\textrm{Re}(a+b)+1<\textrm{Re}(c+d)$.

\section{Some integrals}
\par\setcounter{equation}{0}
\label{integals1}

For the ${}_2F_1$ hypergeometric function we have Euler's integral representation
\begin{equation}
\label{Eulerint}\index{Euler's integral representation for a ${}_2F_1$}
\index{Hypergeometric function!Euler's integral representation}
\hyp{2}{1}{a,b}{c}{z}=\frac{\Gamma(c)}{\Gamma(b)\Gamma(c-b)}
\int_0^1t^{b-1}(1-t)^{c-b-1}(1-zt)^{-a}\,dt,
\end{equation}
where $\textrm{Re}\,c>\textrm{Re}\,b>0$, which holds for $z\in\mathbb{C}\setminus(1,\infty)$.
Here it is understood that $\arg t=\arg(1-t)=0$ and that $(1-zt)^{-a}$ has its
principal value.

We also have Barnes' integral representation
\begin{equation}
\label{Barnes}\index{Barnes' integral representation}
\index{Hypergeometric function!Barnes' integral representation}
\frac{\Gamma(a)\Gamma(b)}{\Gamma(c)}\,\hyp{2}{1}{a,b}{c}{z}=\frac{1}{2\pi i}
\int_{-i\infty}^{i\infty}\frac{\Gamma(a+s)\Gamma(b+s)\Gamma(-s)}{\Gamma(c+s)}(-z)^s\,ds
\end{equation}
for $|z|<1$ with $\arg(-z)<\pi$, where the path of integration is deformed
if necessary, to separate the decreasing poles $s=-a-n$ and $s=-b-n$ from the
increasing poles $s=n$ for $n\in\{0,1,2,\ldots\}$. Such a path always exists if
$a,b\notin\{\ldots,-3,-2,-1\}$.

Secondly, we have the Mellin-Barnes integral or Barnes' first lemma
\begin{eqnarray}
\label{Mellin-Barnes1}\index{Mellin-Barnes integral}\index{Barnes' first lemma}
& &\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}\Gamma(a+s)\Gamma(b+s)\Gamma(c-s)\Gamma(d-s)\,ds\nonumber\\
& &{}=\frac{\Gamma(a+c)\Gamma(a+d)\Gamma(b+c)\Gamma(b+d)}{\Gamma(a+b+c+d)}
\end{eqnarray}
for $\textrm{Re}(a+b+c+d)<1$, where the contour must also be taken in a such a
way that the increasing poles and the decreasing poles remain separate. By using
analytic continuation, one can avoid the condition $\textrm{Re}(a+b+c+d)<1$. The
Barnes integral (\ref{Mellin-Barnes1}) can be seen as a continuous analogue of
Gauss' summation formula (\ref{Gauss}).

We also have a continuous analogue of the Pfaff-Saalsch\"utz summation
formula (\ref{PfaffSaalschutz}) given by the integral, which is also
called Barnes' second lemma\index{Barnes' second lemma},
\begin{eqnarray}
\label{Mellin-Barnes2}
& &\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}
\frac{\Gamma(a+s)\Gamma(b+s)\Gamma(c+s)\Gamma(1-d-s)\Gamma(-s)}{\Gamma(e+s)}\,ds\nonumber\\
& &{}=\frac{\Gamma(a)\Gamma(b)\Gamma(c)\Gamma(1+a-d)\Gamma(1+b-d)\Gamma(1+c-d)}
{\Gamma(e-a)\Gamma(e-b)\Gamma(e-c)}
\end{eqnarray}
with $d+e=a+b+c+1$, where the contour must be taken in a such a way that
the increasing poles and the decreasing poles stay separated.

A continuous analogue of the summation formula (\ref{wellpoised}) for a very-well-poised
${}_5F_4$ is given by Bailey's integral (see also \cite{Bailey35})
\begin{eqnarray}
\label{Bailey1}\index{Bailey's integral}
& &\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}
\frac{\Gamma(1+a/2+s)\Gamma(a+s)\Gamma(b+s)\Gamma(c+s)\Gamma(d+s)\Gamma(b-a-s)\Gamma(-s)}
{\Gamma(a/2+s)\Gamma(1+a-c+s)\Gamma(1+a-d+s)}\,ds\nonumber\\
& &{}=\frac{\Gamma(b)\Gamma(c)\Gamma(d)\Gamma(b+c-a)\Gamma(b+d-a)}
{2\,\Gamma(1+a-c-d)\Gamma(b+c+d-a)}
\end{eqnarray}
which can also be written in a more symmetric form
\begin{eqnarray}
\label{Bailey2}
& &\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}
\frac{\Gamma(a+s)\Gamma(b+s)\Gamma(c+s)\Gamma(d+s)}{\Gamma(a+2s)}\nonumber\\
& &{}\mathindent\times\frac{\Gamma(-s)\Gamma(b-a-s)\Gamma(c-a-s)\Gamma(d-a-s)}{\Gamma(-a-2s)}\,ds\nonumber\\
& &{}=\frac{2\,\Gamma(b)\Gamma(c)\Gamma(d)\Gamma(b+c-a)\Gamma(b+d-a)\Gamma(c+d-a)}{\Gamma(b+c+d-a)}
\end{eqnarray}
and also in the following form due to Wilson (see also \cite{Wilson80})
\begin{eqnarray}
\label{Bailey3}
& &\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}
\frac{\Gamma(a+s)\Gamma(b+s)\Gamma(c+s)\Gamma(d+s)\Gamma(a-s)\Gamma(b-s)\Gamma(c-s)\Gamma(d-s)}
{\Gamma(2s)\Gamma(-2s)}\,ds\nonumber\\
& &{}=\frac{2\,\Gamma(a+b)\Gamma(a+c)\Gamma(a+d)\Gamma(b+c)\Gamma(b+d)\Gamma(c+d)}{\Gamma(a+b+c+d)},
\end{eqnarray}
where the contours must be taken in a such a way that the increasing poles and the
decreasing poles remain separate.

We also mention the integral
\begin{equation}
\label{Slater}
\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}\Gamma(a+s)\Gamma(b-s)z^{-s}\,ds
=\Gamma(a+b)\frac{z^a}{(1+z)^{a+b}}.
\end{equation}
Again the contour must be taken in such a way that the increasing poles of $\Gamma(b-s)$ and
the decreasing poles of $\Gamma(a+s)$ remain separate.

The integrals (\ref{Mellin-Barnes1}) through (\ref{Bailey3}) are all special cases of a more
general formula (id est formula (4.5.1.2) in \cite{Slater}), which has more interesting and
useful special cases such as
\begin{equation}
\label{Slater1}
\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}\frac{\Gamma(a+s)\Gamma(b-s)}{\Gamma(c+s)\Gamma(d-s)}\,ds
=\frac{\Gamma(a+b)\Gamma(c+d-a-b-1)}{\Gamma(c+d-1)\Gamma(c-a)\Gamma(d-b)},
\end{equation}
where the contour must be taken in a such a way that the increasing poles and the decreasing poles
remain separate and
\begin{eqnarray}
\label{Slater2}
& &\frac{1}{2\pi i}\int_{-i\infty}^{i\infty}
\frac{\Gamma(a+s)\Gamma(b+s)\Gamma(c+s)\Gamma(-s)\Gamma(b-a-s)\Gamma(c-a-s)}
{\Gamma(a+2s)\Gamma(-a-2s)}\,ds\nonumber\\
& &{}=\frac{1}{2}\Gamma(b)\Gamma(c)\Gamma(b+c-a),
\end{eqnarray}
where the contour must be taken in a such a way that the increasing poles and the decreasing poles
remain separate.

If $a,b,c,d$ are positive or $b=\overline{a}$ and/or $d=\overline{c}$ and the real parts are
positive, Wilson's integral (\ref{Bailey3}) can be written in the form
\begin{eqnarray}
\label{Wilson1}\index{Wilson's integral}
& &\frac{1}{2\pi}\int_0^{\infty}
\left|\frac{\Gamma(a+ix)\Gamma(b+ix)\Gamma(c+ix)\Gamma(d+ix)}{\Gamma(2ix)}\right|^2\,dx\nonumber\\
& &{}=\frac{\Gamma(a+b)\Gamma(a+c)\Gamma(a+d)\Gamma(b+c)\Gamma(b+d)\Gamma(c+d)}{\Gamma(a+b+c+d)}.
\end{eqnarray}
The limit case $d\rightarrow\infty$ leads to
\begin{equation}
\label{Wilson2}
\frac{1}{2\pi}\int_0^{\infty}
\left|\frac{\Gamma(a+ix)\Gamma(b+ix)\Gamma(c+ix)}{\Gamma(2ix)}\right|^2\,dx
=\Gamma(a+b)\Gamma(a+c)\Gamma(b+c).
\end{equation}

\section{Transformation formulas for generalized hypergeometric functions}
\par\setcounter{equation}{0}
\label{transformation formulas}

In this section we list a number of transformation formulas which can be used to
transform hypergeometric representations and other formulas into equivalent
but different forms.

First of all we have Euler's transformation formula:
\begin{equation}
\label{Eulertrans}\index{Euler's transformation formula}
\index{Transformation formula!Euler}
\hyp{2}{1}{a,b}{c}{z}=(1-z)^{c-a-b}\,\hyp{2}{1}{c-a,c-b}{c}{z}.
\end{equation}

Another transformation formula for the ${}_2F_1$ series, which is also due to Euler, is
\begin{equation}
\label{PfaffKummer}\index{Pfaff-Kummer transformation formula}
\index{Transformation formula!Pfaff-Kummer}
\hyp{2}{1}{a,b}{c}{z}=(1-z)^{-a}\,\hyp{2}{1}{a,c-b}{c}{\frac{z}{z-1}}.
\end{equation}
This transformation formula is also known as the Pfaff or Pfaff-Kummer transformation formula.

As a limit case of the Pfaff-Kummer transformation formula we have Kummer's transformation
formula for the confluent hypergeometric series:
\begin{equation}
\label{Kummer}\index{Kummer's transformation formula}\index{Transformation formula!Kummer}
\hyp{1}{1}{a}{c}{z}=\e^z\,\hyp{1}{1}{c-a}{c}{-z}.
\end{equation}

If we reverse the order of summation in a terminating ${}_1F_1$ series, we
obtain a ${}_2F_0$ series; in fact we have
\begin{equation}
\label{reverse1}
\hyp{1}{1}{-n}{a}{x}=\frac{(-x)^n}{(a)_n}\,\hyp{2}{0}{-n,-a-n+1}{-}{-\frac{1}{x}},
\quad n=0,1,2,\ldots.
\end{equation}
If we apply this technique to a terminating ${}_2F_1$ series, we find
\begin{equation}
\label{reverse2}
\hyp{2}{1}{-n,b}{c}{x}=\frac{(b)_n}{(c)_n}(-x)^n\,\hyp{2}{1}{-n,-c-n+1}{-b-n+1}{\frac{1}{x}},
\quad n=0,1,2,\ldots.
\end{equation}

On the next level we have Whipple's transformation formula for a terminating balanced
${}_4F_3$ series:
\begin{eqnarray}
\label{Whipple}\index{Whipple's transformation formula}\index{Transformation formula!Whipple}
& &\hyp{4}{3}{-n,a,b,c}{d,e,f}{1}\nonumber\\
& &{}=\frac{(e-a)_n(f-a)_n}{(e)_n(f)_n}\hyp{4}{3}{-n,a,d-b,d-c}{d,a-e-n+1,a-f-n+1}{1}
\end{eqnarray}
provided that $a+b+c+1=d+e+f+n$.

\section{The $q$-shifted factorial}
\par\setcounter{equation}{0}
\label{qshifted factorial}

The theory of $q$-analogues or $q$-extensions of classical formulas and
functions is based on the observation that
$$\lim\limits_{q\rightarrow 1}\frac{1-q^{\alpha}}{1-q}=\alpha.$$
Therefore the number $(1-q^{\alpha})/(1-q)$ is sometimes called the
\emph{basic number} $[\alpha]$. For $q\neq 0$ and $q\neq 1$ we define
\begin{equation}
\label{basic}
[\alpha]:=\frac{1-q^{\alpha}}{1-q},
\end{equation}
which implies that
\begin{equation}
\label{basicdef}
[0]=0,\quad [n]=\frac{1-q^n}{1-q}=\sum_{k=0}^{n-1}q^k,\quad n=1,2,3,\ldots.
\end{equation}

Now we can give a $q$-analogue of the Pochhammer symbol $(a)_k$ defined by
(\ref{Pochhammer}):
\begin{equation}
\label{qsh}\index{q-Shifted factorial@$q$-Shifted factorial}
(a;q)_0:=1\quad\textrm{and}\quad (a;q)_k:=\prod_{n=1}^k(1-aq^{n-1})
%  \constraint{ $k=1,2,3,\ldots$ }
\end{equation}
It is clear that
\begin{equation}
\label{limitqsh}
\lim\limits_{q\rightarrow 1}\frac{(q^{\alpha};q)_k}{(1-q)^k}=(\alpha)_k.
\end{equation}
The symbols $(a;q)_k$ are called $q$-shifted factorials. For negative subscripts we define
\begin{equation}
\label{qsh1}
(a;q)_{-k}:=\frac{1}{\displaystyle\prod_{n=1}^{k}(1-aq^{-n})},\quad a\neq q,q^2,q^3,\ldots,q^k,
\quad k=1,2,3,\ldots.
\end{equation}
Now we have
\begin{equation}
\label{qsh2}
(a;q)_{-n}=\frac{1}{(aq^{-n};q)_n}=\frac{(-qa^{-1})^n}{(qa^{-1};q)_n}
q^{\binom{n}{2}},\quad n=0,1,2,\ldots.
\end{equation}

If we replace $q$ by $q^{-1}$, we obtain
\begin{equation}
\label{qsh3}
(a;q^{-1})_n=(a^{-1};q)_n(-a)^nq^{-\binom{n}{2}},\quad a\neq 0.
\end{equation}

We can also define
$$(a;q)_{\infty}=\prod_{k=0}^{\infty}(1-aq^k),\quad 0<|q|<1.$$
This implies that
\begin{equation}
\label{qsh4}
(a;q)_n=\frac{(a;q)_{\infty}}{(aq^n;q)_{\infty}},\quad 0<|q|<1,
\end{equation}
and, for any complex number $\lambda$,
\begin{equation}
\label{qsh5}
(a;q)_{\lambda}=\frac{(a;q)_{\infty}}{(aq^{\lambda};q)_{\infty}},\quad 0<|q|<1,
\end{equation}
where the principal value of $q^{\lambda}$ is taken.

Finally, we list a number of transformation formulas for the $q$-shifted
factorials, where $k$ and $n$ are nonnegative integers:
\begin{equation}
\label{qsh6}
(a;q)_{n+k}=(a;q)_n(aq^n;q)_k,
\end{equation}
\begin{equation}
\label{qsh7}
\frac{(aq^n;q)_k}{(aq^k;q)_n}=\frac{(a;q)_k}{(a;q)_n},
\end{equation}
\begin{equation}
\label{qsh8}
(aq^k;q)_{n-k}=\frac{(a;q)_n}{(a;q)_k},\quad k=0,1,2,\ldots,n,
\end{equation}
\begin{equation}
\label{qsh9}
(a;q)_n=(a^{-1}q^{1-n};q)_n(-a)^nq^{\binom{n}{2}},\quad a\neq 0,
\end{equation}
\begin{equation}
\label{qsh10}
(aq^{-n};q)_n=(a^{-1}q;q)_n(-a)^nq^{-n-\binom{n}{2}},\quad a\neq 0,
\end{equation}
\begin{equation}
\label{qsh11}
\frac{(aq^{-n};q)_n}{(bq^{-n};q)_n}=\frac{(a^{-1}q;q)_n}{(b^{-1}q;q)_n}
\left(\frac{a}{b}\right)^n
%  \constraint{
%    $a\neq 0$ &
%    $b\neq 0$ }
\end{equation}
\begin{equation}
\label{qsh12}
(a;q)_{n-k}=\frac{(a;q)_n}{(a^{-1}q^{1-n};q)_k}\left(-\frac{q}{a}\right)^k
q^{\binom{k}{2}-nk},\quad a\neq 0,\quad k=0,1,2,\ldots,n,
\end{equation}
\begin{eqnarray}
\label{qsh13}
& &\frac{(a;q)_{n-k}}{(b;q)_{n-k}}=\frac{(a;q)_n}{(b;q)_n}
\frac{(b^{-1}q^{1-n};q)_k}{(a^{-1}q^{1-n};q)_k}\left(\frac{b}{a}\right)^k,\nonumber\\
& &{}\mathindent\mathindent\mathindent a\neq 0,\quad b\neq 0,\quad k=0,1,2,\ldots,n,
\end{eqnarray}
\begin{equation}
\label{qsh14}
(q^{-n};q)_k=\frac{(q;q)_n}{(q;q)_{n-k}}(-1)^kq^{\binom{k}{2}-nk},
\quad k=0,1,2,\ldots,n,
\end{equation}
\begin{equation}
\label{qsh15}
(aq^{-n};q)_k=\frac{(a^{-1}q;q)_n}{(a^{-1}q^{1-k};q)_n}(a;q)_kq^{-nk},
\quad a\neq 0,
\end{equation}
\begin{eqnarray}
\label{qsh16}
& &(aq^{-n};q)_{n-k}=\frac{(a^{-1}q;q)_n}{(a^{-1}q;q)_k}
\left(-\frac{a}{q}\right)^{n-k}q^{\binom{k}{2}-\binom{n}{2}},\nonumber\\
& &{}\mathindent\mathindent\mathindent a\neq 0,\quad k=0,1,2,\ldots,n,
\end{eqnarray}
\begin{equation}
\label{qsh17}
(a;q)_{2n}=(a;q^2)_n(aq;q^2)_n,
\end{equation}
\begin{equation}
\label{qsh18}
(a^2;q^2)_n=(a;q)_n(-a;q)_n,
\end{equation}
\begin{equation}
\label{qsh19}
(a;q)_{\infty}=(a;q^2)_{\infty}(aq;q^2)_{\infty},\quad 0<|q|<1,
\end{equation}
\begin{equation}
\label{qsh20}
(a^2;q^2)_{\infty}=(a;q)_{\infty}(-a;q)_{\infty},\quad 0<|q|<1.
\end{equation}

We remark that by using (\ref{qsh18}) we have
\begin{equation}
\label{qsh21}
\frac{1-a^2q^{2n}}{1-a^2}=\frac{(a^2q^2;q^2)_n}{(a^2;q^2)_n}
=\frac{(aq;q)_n(-aq;q)_n}{(a;q)_n(-a;q)_n}.
\end{equation}

\section{The $q$-gamma function and $q$-binomial coefficients}
\par\setcounter{equation}{0}
\label{qgamma function}

The $q$-gamma function is defined by
\begin{equation}
\label{DefqGamma}\index{q-Gamma function@$q$-Gamma function}
\Gamma_q(x):=\frac{(q;q)_{\infty}}{(q^x;q)_{\infty}}(1-q)^{1-x},\quad 0<q<1.
\end{equation}
This is a $q$-analogue of the gamma function given by (\ref{DefGamma}). In fact we have
$$\lim\limits_{q\rightarrow 1}\Gamma_q(x)=\Gamma(x).$$
Note that the $q$-gamma function satisfies the functional equation
\begin{equation}
\label{qGammaFunctional}
\Gamma_q(z+1)=\frac{1-q^z}{1-q}\Gamma_q(z)
%  \constraint{ $\Gamma_q(1)=1$ }
\end{equation}
which is a $q$-extension of the functional equation (\ref{GammaFunctional}) for
the ordinary gamma function.

If we take the principal values of $q^x$ and $(1-q)^{1-x}$ definition (\ref{DefqGamma})
holds for $0<|q|<1$. For $q>1$ the $q$-gamma function can be defined by
\begin{equation}
\label{DefqGamma2}
\Gamma_q(x)=\frac{(q^{-1};q^{-1})_{\infty}}{(q^{-x};q^{-1})_{\infty}}
q^{\binom{x}{2}}(q-1)^{1-x},\quad q>1.
\end{equation}

The $q$-binomial coefficient is defined by
\begin{equation}
\label{DefqBinomial1}\index{q-Binomial coefficient@$q$-Binomial coefficient}
\genfrac{[}{]}{0pt}{}{n}{k}_q:=\frac{(q;q)_n}{(q;q)_k(q;q)_{n-k}}=\genfrac{[}{]}{0pt}{}{n}{n-k}_q,
\quad k=0,1,2,\ldots,n,
\end{equation}
where $n$ denotes a nonnegative integer.

This definition can be generalized in the following way. For arbitrary
complex $\alpha$ we have
\begin{equation}
\label{DefqBinomial2}
\genfrac{[}{]}{0pt}{}{\alpha}{k}_q:=\frac{(q^{-\alpha};q)_k}{(q;q)_k}
(-1)^kq^{k\alpha-\binom{k}{2}}.
\end{equation}
Or more general, for all complex $\alpha$ and $\beta$ and $0<|q|<1$ we have
\begin{equation}
\label{DefqBinomial3}
\genfrac{[}{]}{0pt}{}{\alpha}{\beta}_q:=\frac{\Gamma_q(\alpha+1)}{\Gamma_q(\beta+1)\Gamma_q(\alpha-\beta+1)}
=\frac{(q^{\beta+1};q)_{\infty}(q^{\alpha-\beta+1};q)_{\infty}}
{(q;q)_{\infty}(q^{\alpha+1};q)_{\infty}}.
\end{equation}

For instance this implies that
$$\frac{(q^{\alpha+1};q)_n}{(q;q)_n}=\genfrac{[}{]}{0pt}{}{n+\alpha}{n}_q.$$

Note that
$$\lim\limits_{q\rightarrow 1}\genfrac{[}{]}{0pt}{}{\alpha}{\beta}_q
=\frac{\Gamma(\alpha+1)}{\Gamma(\beta+1)\Gamma(\alpha-\beta+1)}=\binom{\alpha}{\beta}.$$

Finally, we remark that
\begin{equation}
\label{qqn}
\frac{1}{(q;q)_n}=\sum_{k=0}^n\frac{q^k}{(q;q)_k},\quad n=0,1,2,\ldots,
\end{equation}
which can easily be shown by induction, and that
\begin{equation}
\label{aqn}
(a;q)_n=\sum_{k=0}^n\genfrac{[}{]}{0pt}{}{n}{k}_qq^{\binom{k}{2}}(-a)^k,\quad n=0,1,2,\ldots,
\end{equation}
which is a special case of (\ref{qbinomialn}).

\section{Basic hypergeometric functions}
\par\setcounter{equation}{0}\label{hypergeometric}
\label{qhypergeometric functions}

The basic hypergeometric or $q$-hypergeometric function $\mbox{}_r\phi_s$ is defined by the series
\begin{eqnarray}
\label{DefBasHyp}\index{Basic hypergeometric function}
& &\qhyp{r}{s}{a_1,\ldots,a_r}{b_1,\ldots,b_s}{z}\nonumber\\
& &{}:=\sum\limits_{k=0}^{\infty}\frac{(a_1,\ldots,a_r;q)_k}{(b_1,\ldots,b_s;q)_k}
(-1)^{(1+s-r)k}q^{(1+s-r)\binom{k}{2}}\frac{z^k}{(q;q)_k},
\end{eqnarray}
where
$$(a_1,\ldots,a_r;q)_k:=(a_1;q)_k\cdots(a_r;q)_k.$$
Again we assume that the parameters are such that the denominator factors
in the terms of the series are never zero. If one of the numerator
parameters $a_j$ equals $q^{-n}$, where $n$ is a nonnegative integer, this
basic hypergeometric function is a polynomial in $z$. Otherwise the radius of
convergence $\rho$ of the basic hypergeometric series is given by
$$\rho=\left\{\begin{array}{ll}
\displaystyle \infty & \quad\textrm{if}\quad r < s+1\\[5mm]
\displaystyle 1 & \quad\textrm{if}\quad r = s+1\\[5mm]
\displaystyle 0 & \quad\textrm{if}\quad r > s+1.\end{array}\right.$$

The special case $r=s+1$ reads
$$\qhyp{s+1}{s}{a_1,\ldots,a_{s+1}}{b_1,\ldots,b_s}{z}=
\sum\limits_{k=0}^{\infty}\frac{(a_1,\ldots,a_{s+1};q)_k}{(b_1,\ldots,b_s;q)_k}
\frac{z^k}{(q;q)_k}.$$
This basic hypergeometric series was first introduced by Heine in 1846; therefore it is
sometimes called Heine's\index{Heine's series} series. A basic hypergeometric series of
this form is called balanced\index{Basic hypergeometric function!Balanced}
or Saalsch\"{u}tzian\index{Basic hypergeometric function!Saalsch\"{u}tzian} if $z=q$ and
$a_1a_2 \cdots a_{s+1}q=b_1b_2 \cdots b_s$.

The $q$-hypergeometric function is a $q$-analogue of the hypergeometric function
defined by (\ref{DefHyp}) since
$$\lim\limits_{q\rightarrow 1}
\qhyp{r}{s}{q^{a_1},\ldots,q^{a_r}}{q^{b_1},\ldots,q^{b_s}}{(q-1)^{1+s-r}z}
=\hyp{r}{s}{a_1,\ldots,a_r}{b_1,\ldots,b_s}{z}.$$
This limit will be used frequently in chapter~\ref{BasicHyperOrtPol}. In all
cases the hypergeometric series involved is in fact a polynomial so that
convergence is guaranteed.

In the sequel of this paragraph we also assume that each (basic) hypergeometric
function is in fact a polynomial. We remark that
$$\lim\limits_{a_r\rightarrow\infty}
\qhyp{r}{s}{a_1,\ldots,a_r}{b_1,\ldots,b_s}{\frac{z}{a_r}}=
\qhyp{r-1}{s}{a_1,\ldots,a_{r-1}}{b_1,\ldots,b_s}{z}.$$
In fact this is the reason for the factors
$(-1)^{(1+s-r)k}q^{(1+s-r)\binom{k}{2}}$ in the definition (\ref{DefBasHyp})
of the basic hypergeometric function.

Many limit relations between basic hypergeometric orthogonal polynomials
are based on the observations that
\begin{equation}
\label{qhypsub}
\qhyp{r}{s}{a_1,\ldots,a_{r-1},\mu}{b_1,\ldots,b_{s-1},\mu}{z}=
\qhyp{r-1}{s-1}{a_1,\ldots,a_{r-1}}{b_1,\ldots,b_{s-1}}{z},
\end{equation}
\begin{equation}
\label{qhyplim1}
\lim\limits_{\lambda\rightarrow\infty}
\qhyp{r}{s}{a_1,\ldots,a_{r-1},\lambda a_r}{b_1,\ldots,b_s}{\frac{z}{\lambda}}
=\qhyp{r-1}{s}{a_1,\ldots,a_{r-1}}{b_1,\ldots,b_s}{a_rz},
\end{equation}
\begin{equation}
\label{qhyplim2}
\lim\limits_{\lambda\rightarrow\infty}
\qhyp{r}{s}{a_1,\ldots,a_r}{b_1,\ldots,b_{s-1},\lambda b_s}{\lambda z}=
\qhyp{r}{s-1}{a_1,\ldots,a_r}{b_1,\ldots,b_{s-1}}{\frac{z}{b_s}},
\end{equation}
and
\begin{equation}
\label{qhyplim3}
\lim\limits_{\lambda\rightarrow\infty}
\qhyp{r}{s}{a_1,\ldots,a_{r-1},\lambda a_r}{b_1,\ldots,b_{s-1},\lambda b_s}{z}
=\qhyp{r-1}{s-1}{a_1,\ldots,a_{r-1}}{b_1,\ldots,b_{s-1}}{\frac{a_rz}{b_s}}.
\end{equation}

Mostly, the left-hand side of (\ref{qhypsub}) occurs as a limit case when some numerator
parameter and some denominator parameter tend to the same value.

All families of discrete orthogonal polynomials $\{P_n(x)\}_{n=0}^N$ are
defined for $n=0,1,2,\ldots,N$, where $N$ is a positive integer. In these
cases something like (\ref{qhypsub}) occurs in the basic hypergeometric representation
when $n=N$. In these cases we have to be aware of the fact that we still have a polynomial
(in that case of degree $N$). For instance, if we take $n=N$ in the basic hypergeometric
representation (\ref{DefqHahn}) of the $q$-Hahn polynomials, we have
$$Q_N(q^{-x};\alpha,\beta,N|q)=\sum_{k=0}^N
\frac{(\alpha\beta q^{N+1};q)_k(q^{-x};q)_k}{(\alpha q;q)_k(q;q)_k}q^k.$$
So these cases must be understood by continuity.

\section{The $q$-binomial theorem and other summation formulas}
\par\setcounter{equation}{0}
\label{qsummation formulas}

A $q$-analogue of the binomial theorem (\ref{binomial}) is called the $q$-binomial theorem:
\begin{equation}
\label{qbinomial}\index{q-Binomial theorem@$q$-Binomial theorem}
\index{Summation formula!q-Binomial theorem@$q$-Binomial theorem}
\qhyp{1}{0}{a}{-}{z}=\sum_{n=0}^{\infty}\frac{(a;q)_n}{(q;q)_n}z^n=
\frac{(az;q)_{\infty}}{(z;q)_{\infty}},\quad 0<|q|<1,\quad |z|<1.
\end{equation}
For $a=q^{-n}$ with $n$ a nonnegative integer we find
\begin{equation}
\label{qbinomialn}
\qhyp{1}{0}{q^{-n}}{-}{z}=(zq^{-n};q)_n,\quad n=0,1,2,\ldots.
\end{equation}
In fact this is a $q$-analogue of Newton's binomium (\ref{Newton}).
Note that the case $a=0$ of (\ref{qbinomial}) is the limit case ($n\rightarrow\infty$) of (\ref{qqn}).

Gauss's summation formula (\ref{Gauss}) and the Vandermonde or Chu-Vandermonde
summation formula (\ref{ChuVandermonde}) have the following $q$-analogues:
\begin{equation}
\label{qChuVandermonde1}\index{q-Gauss summation formula@$q$-Gauss summation formula}
\index{Summation formula!q-Gauss@$q$-Gauss}
\qhyp{2}{1}{a,b}{c}{\frac{c}{ab}}=\frac{(a^{-1}c,b^{-1}c;q)_{\infty}}
{(c,a^{-1}b^{-1}c;q)_{\infty}},\quad 0<|q|<1,\quad\left|\frac{c}{ab}\right|<1,
\end{equation}
\begin{equation}
\label{qChuVandermonde2}\index{q-Vandermonde summation formula@$q$-Vandermonde summation formula}
\index{Summation formula!q-Vandermonde@$q$-Vandermonde}
\index{q-Chu-Vandermonde summation formula@$q$-Chu-Vandermonde summation formula}
\index{Summation formula!q-Chu-Vandermonde@$q$-Chu-Vandermonde}
\qhyp{2}{1}{q^{-n},b}{c}{\frac{cq^n}{b}}=\frac{(b^{-1}c;q)_n}{(c;q)_n},\quad n=0,1,2,\ldots
\end{equation}
and
\begin{equation}
\label{qChuVandermonde3}
\qhyp{2}{1}{q^{-n},b}{c}{q}=\frac{(b^{-1}c;q)_n}{(c;q)_n}b^n,\quad n=0,1,2,\ldots.
\end{equation}
By taking the limit $b\rightarrow\infty$ in (\ref{qChuVandermonde1}) we also obtain a summation
formula for the ${}_1\phi_1$ series:
\begin{equation}
\label{sum1phi1}\index{Summation formula!for a ${}_1\phi_1$}
\qhyp{1}{1}{a}{c}{\frac{c}{a}}=\frac{(a^{-1}c;q)_{\infty}}{(c;q)_{\infty}},\quad 0<|q|<1.
\end{equation}
By taking the limit $c\rightarrow\infty$ in (\ref{qChuVandermonde2}) we obtain a summation
formula for a terminating ${}_2\phi_0$ series:
\begin{equation}
\label{sum2phi0}\index{Summation formula!for a terminating ${}_2\phi_0$}
\qhyp{2}{0}{q^{-n},b}{-}{\frac{q^n}{b}}=\frac{1}{b^n},\quad n=0,1,2,\ldots.
\end{equation}
By taking the limit $a\rightarrow\infty$ in (\ref{sum1phi1}) we obtain
\begin{equation}
\label{sum0phi1}\index{Summation formula!for a ${}_0\phi_1$}
\qhyp{0}{1}{-}{c}{c}=\frac{1}{(c;q)_{\infty}},\quad 0<|q|<1.
\end{equation}

On the ${}_3\phi_2$ level we have the summation formula
\begin{equation}
\label{qPfaffSaalschutz}
\index{q-Saalschutz summation formula@$q$-Saalsch\"{u}tz summation formula}
\index{Summation formula!q-Saalschutz@$q$-Saalsch\"{u}tz}
\index{q-Pfaff-Saalschutz summation formula@$q$-Pfaff-Saalsch\"{u}tz summation formula}
\index{Summation formula!q-Pfaff-Saalschutz@$q$-Pfaff-Saalsch\"{u}tz}
\qhyp{3}{2}{q^{-n},a,b}{c,abc^{-1}q^{1-n}}{q}=\frac{(a^{-1}c,b^{-1}c;q)_n}
{(c,a^{-1}b^{-1}c;q)_n},\quad n=0,1,2,\ldots,
\end{equation}
which is a $q$-analogue of the Saalsch\"utz or Pfaff-Saalsch\"utz summation formula
(\ref{PfaffSaalschutz}).

On the ${}_6\phi_5$ level we have the Jackson summation formula
\begin{eqnarray}
\label{qJackson1}\index{Jackson's summation formula}\index{Summation formula!Jackson}
\index{Summation formula!for a very-well-poised ${}_6\phi_5$}
& &\qhyp{6}{5}{q\sqrt{a},-q\sqrt{a},a,b,c,d}{\sqrt{a},-\sqrt{a},ab^{-1}q,ac^{-1}q,ad^{-1}q}{\frac{aq}{bcd}}\nonumber\\
& &{}=\frac{(aq,ab^{-1}c^{-1}q,ab^{-1}d^{-1}q,ac^{-1}d^{-1}q;q)_{\infty}}
{(ab^{-1}q,ac^{-1}q,ad^{-1}q,ab^{-1}c^{-1}d^{-1}q;q)_{\infty}},\quad\left|\frac{aq}{bcd}\right|<1
\end{eqnarray}
for a non-terminating very-well-poised ${}_6\phi_5$. We also have the summation formula
\begin{eqnarray}
\label{qJackson2}
& &\qhyp{6}{5}{q\sqrt{a},-q\sqrt{a},a,b,c,q^{-n}}{\sqrt{a},-\sqrt{a},ab^{-1}q,ac^{-1}q,aq^{n+1}}{\frac{aq^{n+1}}{bc}}\nonumber\\
& &{}=\frac{(aq,ab^{-1}c^{-1}q;q)_n}{(ab^{-1}q,ac^{-1}q;q)_n},\quad n=0,1,2,\ldots
\end{eqnarray}
for a terminating very-well-poised ${}_6\phi_5$, which is also due to Jackson.
By taking the limit $c\rightarrow 0$ we obtain
\begin{eqnarray}
\label{qJackson3}
& &\qhyp{6}{4}{q\sqrt{a},-q\sqrt{a},a,b,0,q^{-n}}{\sqrt{a},-\sqrt{a},ab^{-1}q,aq^{n+1}}{\frac{q^n}{b}}\nonumber\\
& &{}=\frac{(aq;q)_n}{(ab^{-1}q;q)_n}b^{-n},\quad n=0,1,2,\ldots.
\end{eqnarray}
If we take the limit $b\rightarrow 0$ we obtain
\begin{eqnarray}
\label{qJackson4}
& &\qhyp{6}{3}{q\sqrt{a},-q\sqrt{a},a,0,0,q^{-n}}{\sqrt{a},-\sqrt{a},aq^{n+1}}{\frac{q^{n-1}}{a}}\nonumber\\
& &{}=(-1)^na^{-n}q^{-\binom{n+1}{2}}(aq;q)_n,\quad n=0,1,2,\ldots.
\end{eqnarray}

\section{More integrals}
\par\setcounter{equation}{0}
\label{integrals2}

In this section we list some $q$-extensions of the beta integral.
For instance, we will need the following integral:
\begin{equation}
\label{int1}
\int_0^{\infty}x^{c-1}\frac{(-ax,-bq/x;q)_{\infty}}{(-x,-q/x;q)_{\infty}}\,dx
=\frac{\pi}{\sin(\pi c)}\,\frac{(ab,q^c,q^{1-c};q)_{\infty}}{(bq^c,aq^{-c},q;q)_{\infty}},
\end{equation}
which holds for $0<q<1$, $\textrm{Re}\,c>0$ and $\left|aq^{-c}\right|<1$.
If we set $b=1$ in (\ref{int1}), we find that
\begin{equation}
\label{int2}
\int_0^{\infty}x^{c-1}\frac{(-ax;q)_{\infty}}{(-x;q)_{\infty}}\,dx
=\frac{\pi}{\sin(\pi c)}\,\frac{(a,q^{1-c};q)_{\infty}}{(aq^{-c},q;q)_{\infty}}
\end{equation}
for $0<q<1$, $\textrm{Re}\,c>0$ and $\left|aq^{-c}\right|<1$,
and by taking the limit $c\rightarrow 1$ in (\ref{int1}), we obtain
\begin{equation}
\label{int3}
\int_0^{\infty}\frac{(-ax,-bq/x;q)_{\infty}}{(-x,-q/x;q)_{\infty}}\,dx
=-\ln q\,\frac{(ab,q;q)_{\infty}}{(bq,a/q;q)_{\infty}}
\end{equation}
for $0<q<1$ and $\left|aq^{-1}\right|<1$.

Finally, we mention the Askey-Wilson $q$-beta integral
\begin{equation}
\label{AskeyWilsonIntegral}\index{Askey-Wilson integral}
\index{Askey-Wilson q-beta integral@Askey-Wilson $q$-beta integral}
\index{q-Beta integral@$q$-Beta integral}
\frac{1}{2\pi}\int_{-1}^1\frac{w(x)}{\sqrt{1-x^2}}\,dx=\frac{1}{2\pi}\int_0^{\pi}w(\cos\theta)\,d\theta
=\frac{(abcd;q)_{\infty}}{(ab,ac,ad,bc,bd,cd,q;q)_{\infty}},
\end{equation}
where
\begin{eqnarray*}
w(x)&=&\frac{h(x,1)h(x,-1)h(x,q^{1/2})h(x,-q^{1/2})}{h(x,a)h(x,b)h(x,c)h(x,d)}
=\left|\frac{(\e^{2i\theta};q)_{\infty}}{(a\e^{i\theta},b\e^{i\theta},c\e^{i\theta},d\e^{i\theta};q)_{\infty}}\right|^2\\
&=&\frac{(\e^{2i\theta},\e^{-2i\theta};q)_{\infty}}
{(a\e^{i\theta},a\e^{-i\theta},b\e^{i\theta},b\e^{-i\theta},c\e^{i\theta},c\e^{-i\theta},d\e^{i\theta},d\e^{-i\theta};q)_{\infty}},
\quad x=\cos\theta
\end{eqnarray*}
with
\begin{eqnarray*}
h(x,\alpha)&=&\prod_{k=0}^{\infty}\left(1-2\alpha xq^k+\alpha^2q^{2k}\right)\\
&=&\left|(\alpha \e^{i\theta};q)_{\infty}\right|^2
=\left(\alpha \e^{i\theta},\alpha \e^{-i\theta};q\right)_{\infty},\quad x=\cos\theta.
\end{eqnarray*}
The Askey-Wilson integral (\ref{AskeyWilsonIntegral}) is a $q$-analogue of Wilson's integral
(\ref{Wilson1}) and holds for $\max(|a|,|b|,|c|,|d|)<1$ and $a,b,c,d$ positive or
$b=\overline{a}$ and/or $d=\overline{c}$ with positive real parts.

\section{Transformation formulas for basic hypergeometric functions}
\par\setcounter{equation}{0}
\label{qtransformation formulas}

In this section we list a number of transformation formulas which can be used to
transform basic hypergeometric representations and other formulas into equivalent
but different forms.

First of all we have Heine's transformation formulas for the ${}_2\phi_1$ series:
\begin{eqnarray}
\label{Heine1}\index{Heine's transformation formula}\index{Transformation formula!Heine}
\qhyp{2}{1}{a,b}{c}{z}&=&\frac{(az,b;q)_{\infty}}{(c,z;q)_{\infty}}\,
\qhyp{2}{1}{b^{-1}c,z}{az}{b}\\
&=&\frac{(b^{-1}c,bz;q)_{\infty}}{(c,z;q)_{\infty}}\,
\qhyp{2}{1}{abc^{-1}z,b}{bz}{\frac{c}{b}}\label{Heine2}\\
&=&\frac{(abc^{-1}z;q)_{\infty}}{(z;q)_{\infty}}\,
\qhyp{2}{1}{a^{-1}c,b^{-1}c}{c}{\frac{abz}{c}}.\label{Heine3}
\end{eqnarray}

The latter formula is a $q$-analogue of Euler's transformation formula:
\begin{equation}
\label{qEulertrans}
\index{q-Euler transformation formula@$q$-Euler transformation formula}
\index{Transformation formula!q-Euler@$q$-Euler}
\hyp{2}{1}{a,b}{c}{z}=(1-z)^{c-a-b}\,\hyp{2}{1}{c-a,c-b}{c}{z}.
\end{equation}

Another transformation formula for the ${}_2\phi_1$ series is
\begin{equation}
\label{qPfaffKummer}
\index{q-Pfaff-Kummer transformation formula@$q$-Pfaff-Kummer transformation formula}
\index{Transformation formula!q-Pfaff-Kummer@$q$-Pfaff-Kummer}
\qhyp{2}{1}{a,b}{c}{z}=\frac{(az;q)_{\infty}}{(z;q)_{\infty}}\,
\qhyp{2}{2}{a,b^{-1}c}{c,az}{bz},
\end{equation}
which is a $q$-analogue of the Pfaff-Kummer transformation formula (\ref{PfaffKummer}).

Limit cases of Heine's transformation formulas are
\begin{eqnarray}
\label{Heinelimit1}
\qhyp{2}{1}{a,0}{c}{z}
&=&\frac{(az;q)_{\infty}}{(c,z;q)_{\infty}}\,\qhyp{1}{1}{z}{az}{c}\\
&=&\frac{1}{(z;q)_{\infty}}\,\qhyp{1}{1}{a^{-1}c}{c}{az},\label{Heinelimit2}
\end{eqnarray}
\begin{eqnarray}
\label{Heinelimit3}
\qhyp{2}{1}{0,0}{c}{z}
&=&\frac{1}{(c,z;q)_{\infty}}\,\qhyp{1}{1}{z}{0}{c}\\
&=&\frac{1}{(z;q)_{\infty}}\,\qhyp{0}{1}{-}{c}{cz},\label{Heinelimit4}
\end{eqnarray}
\begin{eqnarray}
\label{Heinelimit5}
\qhyp{1}{1}{a}{c}{z}
&=&\frac{(a,z;q)_{\infty}}{(c;q)_{\infty}}\,\qhyp{2}{1}{a^{-1}c,0}{z}{a}\\
&=&(ac^{-1}z;q)_{\infty}\cdot\qhyp{2}{1}{a^{-1}c,0}{c}{\frac{az}{c}}\label{Heinelimit6}
\end{eqnarray}
and
\begin{eqnarray}
\label{Heinelimit7}
\qhyp{2}{1}{a,b}{0}{z}
&=&\frac{(az,b;q)_{\infty}}{(z;q)_{\infty}}\,\qhyp{2}{1}{z,0}{az}{b}\\
&=&\frac{(bz;q)_{\infty}}{(z;q)_{\infty}}\,\qhyp{1}{1}{b}{bz}{az}.\label{Heinelimit8}
\end{eqnarray}

The $q$-analogues of (\ref{reverse1}) and (\ref{reverse2}) are
\begin{equation}
\label{qreverse1}
\qhyp{1}{1}{q^{-n}}{a}{z}=\frac{(q^{-1}z)^n}{(a;q)_n}\,
\qhyp{2}{1}{q^{-n},a^{-1}q^{1-n}}{0}{\frac{aq^{n+1}}{z}}
\end{equation}
for $n=0,1,2,\ldots$, and
\begin{eqnarray}
\label{qreverse2}
& &\qhyp{2}{1}{q^{-n},b}{c}{z}\nonumber\\
& &=\frac{(b;q)_n}{(c;q)_n}q^{-n-\binom{n}{2}}(-z)^n\,
\qhyp{2}{1}{q^{-n},c^{-1}q^{1-n}}{b^{-1}q^{1-n}}{\frac{cq^{n+1}}{bz}}
\end{eqnarray}
for $n=0,1,2,\ldots$.

A limit case of the latter formula is
\begin{equation}
\label{qreverse3}
\qhyp{2}{0}{q^{-n},b}{-}{zq^n}=(b;q)_nz^n\,
\qhyp{2}{1}{q^{-n},0}{b^{-1}q^{1-n}}{\frac{q}{bz}}
\end{equation}
for $n=0,1,2,\ldots$.

The next transformation formula is due to Jackson:
\begin{equation}
\label{Jackson1}\index{Jackson's transformation formula}\index{Transformation formula!Jackson}
\qhyp{2}{1}{q^{-n},b}{c}{z}=\frac{(bc^{-1}q^{-n}z;q)_{\infty}}
{(bc^{-1}z;q)_{\infty}}\,\qhyp{3}{2}{q^{-n},b^{-1}c,0}{c,b^{-1}cqz^{-1}}{q}
\end{equation}
for $n=0,1,2,\ldots$. Equivalently, we have
\begin{equation}
\label{Jackson2}
\qhyp{3}{2}{q^{-n},a,0}{b,c}{q}=\frac{(b^{-1}q;q)_{\infty}}
{(b^{-1}q^{1-n};q)_{\infty}}\,\qhyp{2}{1}{q^{-n},a^{-1}c}{c}{\frac{aq}{b}}
\end{equation}
for $n=0,1,2,\ldots$.

Other transformation formulas of this kind are given by:
\begin{eqnarray}
\label{Jackson3}
& &\qhyp{2}{1}{q^{-n},b}{c}{z}\nonumber\\
& &{}=\frac{(b^{-1}c;q)_n}{(c;q)_n}\left(\frac{bz}{q}\right)^n\,
\qhyp{3}{2}{q^{-n},qz^{-1},c^{-1}q^{1-n}}{bc^{-1}q^{1-n},0}{q}\\
& &{}=\frac{(b^{-1}c;q)_n}{(c;q)_n}\,\qhyp{3}{2}{q^{-n},b,bc^{-1}q^{-n}z}
{bc^{-1}q^{1-n},0}{q}\label{Jackson4}
\end{eqnarray}
for $n=0,1,2,\ldots$, or equivalently
\begin{eqnarray}
\label{Jackson5}
\qhyp{3}{2}{q^{-n},a,b}{c,0}{q}&=&
\frac{(b;q)_n}{(c;q)_n}a^n\,\qhyp{2}{1}{q^{-n},b^{-1}c}{b^{-1}q^{1-n}}{\frac{q}{a}}\\
&=&\frac{(a^{-1}c;q)_n}{(c;q)_n}a^n\,\qhyp{2}{1}{q^{-n},a}{ac^{-1}q^{1-n}}{\frac{bq}{c}}\label{Jackson6}
\end{eqnarray}
for $n=0,1,2,\ldots$.

Limit cases of these formulas are
\begin{equation}
\label{Jacksonlimit1}
\qhyp{2}{0}{q^{-n},b}{-}{z}=b^{-n}\,
\qhyp{3}{2}{q^{-n},b,bzq^{-n}}{0,0}{q},\quad n=0,1,2,\ldots,
\end{equation}
or equivalently
\begin{eqnarray}
\label{Jacksonlimit2}
\qhyp{3}{2}{q^{-n},a,b}{0,0}{q}&=&(b;q)_na^n\,
\qhyp{2}{1}{q^{-n},0}{b^{-1}q^{1-n}}{\frac{q}{a}}\\
&=&a^n\,\qhyp{2}{0}{q^{-n},a}{-}{\frac{bq^n}{a}}\label{Jacksonlimit3}
\end{eqnarray}
for $n=0,1,2,\ldots$.

On the next level we have Sears' transformation formula for a terminating
balanced ${}_4\phi_3$ series:
\begin{eqnarray}
\label{Sears1}\index{Sears' transformation formula}\index{Transformation formula!Sears}
& &\qhyp{4}{3}{q^{-n},a,b,c}{d,e,f}{q}\nonumber\\
& &{}=\frac{(a^{-1}e,a^{-1}f;q)_n}{(e,f;q)_n}a^n\,\qhyp{4}{3}{q^{-n},a,b^{-1}d,c^{-1}d}
{d,ae^{-1}q^{1-n},af^{-1}q^{1-n}}{q}\\
& &{}=\frac{(a,a^{-1}b^{-1}ef,a^{-1}c^{-1}ef;q)_n}{(e,f,a^{-1}b^{-1}c^{-1}ef;q)_n}\nonumber\\
& &{}\mathindent\times\qhyp{4}{3}{q^{-n},a^{-1}e,a^{-1}f,a^{-1}b^{-1}c^{-1}ef}
{a^{-1}b^{-1}ef,a^{-1}c^{-1}ef,a^{-1}q^{1-n}}{q},\label{Sears2}
\end{eqnarray}
provided that $def=abcq^{1-n}$.
Sears' transformation formula is a $q$-analogue of Whipple's transformation (\ref{Whipple}).

Finally, we have a quadratic transformation formula which is due to Singh:
\begin{equation}
\label{Singh}\index{Singh's transformation formula}\index{Transformation formula!Singh}
\qhyp{4}{3}{a^2,b^2,c,d}{abq^{1/2},-abq^{1/2},-cd}{q}=
\mbox{}_4\phi_3\left(\genfrac{}{}{0pt}{}{a^2,b^2,c^2,d^2}{a^2b^2q,-cd,-cdq}\,;\,q^2,q^2\right),
\end{equation}
which is valid when both sides terminate.

\section{Some $q$-analogues of special functions}
\par\setcounter{equation}{0}
\label{special functions}

For the exponential function we have two different natural $q$-extensions,
denoted by ${\mathrm e}_q(z)$ and $\E_q(z)$, which can be defined by
\begin{equation}
\label{qexp1}\index{q-Exponential function@$q$-Exponential function}
{\mathrm e}_q(z):=\qhyp{1}{0}{0}{-}{z}=\sum_{n=0}^{\infty}\frac{z^n}{(q;q)_n}
=\frac{1}{(z;q)_{\infty}}
%  \constraint{
%    $0<|q|<1$ &
%    $|z|<1$ }
\end{equation}
and
\begin{equation}
\label{qexp2}
\E_q(z):=\qhyp{0}{0}{-}{-}{-z}=
\sum_{n=0}^{\infty}\frac{q^{\binom{n}{2}}}{(q;q)_n}z^n=(-z;q)_{\infty},\quad 0<|q|<1.
\end{equation}
These $q$-analogues of the exponential function are related by
$$\qexpKLS{q}@{z}\qExpKLS@{-z}=1.$$

They are $q$-extensions of the exponential function since
$$\lim\limits_{q\rightarrow 1}{\mathrm e}_q((1-q)z)=\lim\limits_{q\rightarrow 1}\E_q((1-q)z)=\e^z.$$

Note that (\ref{qexp1}) can be seen as the special case $a=0$ of (\ref{qbinomial}).

If we assume that $0<|q|<1$ and $|z|<1$, we may define
\begin{equation}
\label{qcos1}
\cos_q(z):=\frac{{\mathrm e}_q(iz)+{\mathrm e}_q(-iz)}{2}=
\sum_{n=0}^{\infty}\frac{(-1)^nz^{2n}}{(q;q)_{2n}}
\end{equation}
and
\begin{equation}
\label{qsin1}
\sin_q(z):=\frac{{\mathrm e}_q(iz)-{\mathrm e}_q(-iz)}{2i}=
\sum_{n=0}^{\infty}\frac{(-1)^nz^{2n+1}}{(q;q)_{2n+1}}.
\end{equation}
These are $q$-analogues of the trigonometric functions $\cos z$ and $\sin z$.
On the other hand, we may define
\begin{equation}
\label{qcos2}
\textrm{Cos}_q(z):=\frac{\E_q(iz)+\E_q(-iz)}{2}
=\sum_{n=0}^{\infty}\frac{(-1)^nq^{\binom{2n}{2}}z^{2n}}{(q;q)_{2n}}
\end{equation}
and
\begin{equation}
\label{qsin2}
\textrm{Sin}_q(z):=\frac{\E_q(iz)-\E_q(-iz)}{2i}
=\sum_{n=0}^{\infty}\frac{(-1)^nq^{\binom{2n+1}{2}}z^{2n+1}}{(q;q)_{2n+1}}.
\end{equation}
Then we have
$${\mathrm e}_q(iz)=\cos_q(z)+i\sin_q(z)\quad\textrm{and}\quad \E_q(iz)=\textrm{Cos}_q(z)+i\:\textrm{Sin}_q(z).$$
Further we have
$$\left\{\begin{array}{l}\cos_q(z)\textrm{Cos}_q(z)+\sin_q(z)\textrm{Sin}_q(z)=1\\[5mm]
\sin_q(z)\textrm{Cos}_q(z)-\cos_q(z)\textrm{Sin}_q(z)=0.\end{array}\right.$$
The $q$-analogues of the trigonometric functions can be used to find
different forms of formulas appearing in this book, although we will not
use them.

Some $q$-analogues of the Bessel functions are given by
\begin{equation}
\label{qBessel1}\index{q-Bessel function@$q$-Bessel function}
\index{Jackson's q-Bessel function@Jackson's $q$-Bessel function}
J_{\nu}^{(1)}(z;q):=\frac{(q^{\nu+1};q)_{\infty}}{(q;q)_{\infty}}
\left(\frac{z}{2}\right)^{\nu}\,\qhyp{2}{1}{0,0}{q^{\nu+1}}{-\frac{z^2}{4}},\quad |z|<2
\end{equation}
and
\begin{equation}
\label{qBessel2}
J_{\nu}^{(2)}(z;q):=\frac{(q^{\nu+1};q)_{\infty}}{(q;q)_{\infty}}
\left(\frac{z}{2}\right)^{\nu}\,\qhyp{0}{1}{-}{q^{\nu+1}}{-\frac{q^{\nu+1}z^2}{4}}.
\end{equation}
These $q$-Bessel functions are connected by
$$J_{\nu}^{(2)}(z;q)=(-\frac{z^2}{4};q)_{\infty}\cdot J_{\nu}^{(1)}(z;q),\quad |z|<2.$$
They are $q$-extensions of the Bessel function of the first kind since
$$\lim\limits_{q\rightarrow 1}J_{\nu}^{(k)}((1-q)z;q)=J_{\nu}(z),\quad k=1,2.$$

These $q$-Bessel functions were introduced by F.H.~Jackson in 1905 and
are therefore referred to as Jackson's $q$-Bessel functions. A third
$q$-analogue of the Bessel function is given by
\begin{equation}
\label{qBessel3}
J_{\nu}^{(3)}(z;q):=\frac{(q^{\nu+1};q)_{\infty}}{(q;q)_{\infty}}
z^{\nu}\,\qhyp{1}{1}{0}{q^{\nu+1}}{qz^2}.
\end{equation}
This third $q$-Bessel function is also known as the Hahn-Exton $q$-Bessel function.
\index{Hahn-Exton q-Bessel function@Hahn-Exton $q$-Bessel function}
This is also a $q$-extension of the Bessel function of the first kind since
$$\lim\limits_{q\rightarrow 1}J_{\nu}^{(3)}((1-q)z;q)=J_{\nu}(2z).$$

\section{The $q$-derivative and $q$-integral}
\par\setcounter{equation}{0}
\label{qderivative}

For $q\neq 1$ the $q$-derivative operator $\mathcal{D}_q$ is defined by
\begin{equation}
\label{qderiv1}\index{q-Derivative operator@$q$-Derivative operator}
\mathcal{D}_qf(z):=\left\{\begin{array}{ll}
\displaystyle \frac{f(z)-f(qz)}{(1-q)z}, & z\neq 0\\[5mm]
f'(0), & z=0.\end{array}\right.
\end{equation}
Further we define
\begin{equation}
\label{qderiv2}
\mathcal{D}_q^0f:=f\quad\textrm{and}\quad
\mathcal{D}_q^nf:=\mathcal{D}_q\left(\mathcal{D}_q^{n-1}f\right),
%  \constraint{$n=1,2,3,\ldots$}
\end{equation}
It is not very difficult to see that
$$\lim\limits_{q\rightarrow 1}\mathcal{D}_qf(z)=f'(z)$$
if the function $f$ is differentiable at $z$.

The $q$-derivative operator is a special case of Hahn's $q$-operator, which will be defined in
section~\ref{Hahnoperator}. This operator also generalizes the differentiation operator $D=d/dx$.

An easy consequence of the definition (\ref{qderiv1}) is
\begin{equation}
\label{qderiv3}
\mathcal{D}_q\left[f(\gamma x)\right]=\gamma\left(\mathcal{D}_qf\right)(\gamma x)
\end{equation}
for all $\gamma\in\mathbb{C}$, or more general
\begin{equation}
\label{qderiv4}
\mathcal{D}_q^n\left[f(\gamma x)\right]=\gamma^n\left(\mathcal{D}_q^nf\right)(\gamma x),
\quad n=0,1,2,\ldots.
\end{equation}

Further we have
\begin{equation}
\label{qderiv5}
\mathcal{D}_q\left[f(x)g(x)\right]=
f(qx)\mathcal{D}_qg(x)+g(x)\mathcal{D}_qf(x)
\end{equation}
which is often referred to as the $q$-product rule. This can be generalized
to a $q$-analogue of Leibniz' rule:
\begin{equation}
\label{qderiv6}
\mathcal{D}_q^n\left[f(x)g(x)\right]=\sum_{k=0}^n\genfrac{[}{]}{0pt}{}{n}{k}_q
\left(\mathcal{D}_q^{n-k}f\right)(q^kx)\left(\mathcal{D}_q^kg\right)(x),
\quad n=0,1,2,\ldots.
\end{equation}

The $q$-integral is defined by
\begin{equation}
\label{qint1}\index{q-Integral@$q$-Integral}
\index{Jackson-Thomae q-integral@Jackson-Thomae $q$-integral}
\int_0^zf(t)\,d_qt:=z(1-q)\sum_{n=0}^{\infty}f(q^nz)q^n,\quad 0<q<1.
\end{equation}
This definition is due to J.~Thomae (1869) and F.H.~Jackson (1910). Jackson also defined a
$q$-integral on $(0,\infty)$ by
\begin{equation}
\label{qint2}
\int_0^{\infty}f(t)\,d_qt:=(1-q)\sum_{n=-\infty}^{\infty}f(q^n)q^n,\quad 0<q<1.
\end{equation}
If the function $f$ is continuous on $[0,z]$, we have
$$\lim\limits_{q\rightarrow 1}\int_0^zf(t)\,d_qt=\int_0^zf(t)\,dt.$$
Of course, definition (\ref{qint1}) implies that
$$\int_a^bf(t)\,d_qt=b(1-q)\sum_{n=0}^{\infty}f(bq^n)q^n-a(1-q)\sum_{n=0}^{\infty}f(aq^n)q^n,\quad 0<q<1$$
and definition (\ref{qint2}) implies that
$$\int_{-\infty}^{\infty}f(t)\,d_qt=(1-q)\sum_{n=-\infty}^{\infty}\left\{f(q^n)+f(-q^n)\right\}q^n,\quad 0<q<1.$$

\noindent
A function $f$ is called $q$-integrable if the appropriate sum converges absolutely.

\noindent
We remark that we have
$$F(z)=\int_0^zf(t)\,d_qt\quad\Longrightarrow\quad\mathcal{D}_qF(z)=f(z)$$
and
$$\int_a^b\mathcal{D}_qf(t)\,d_qt=f(b)-f(a).$$
The $q$-productrule (\ref{qderiv5}) implies the $q$-integration by parts formula
\begin{equation}
\label{qpartint}
\int_a^bg(x)\mathcal{D}_qf(x)\,d_qx=\Big[f(x)g(x)\Big]_a^b-\int_a^bf(qx)\mathcal{D}_qg(x)\,d_qx
\end{equation}
for suitable functions $f$ and $g$.

\vspace{5mm}

\noindent
Finally, we mention the following $q$-integral formula (see \cite{GasperRahman90}, formula (2.10.18))
\begin{eqnarray}
\label{qint3}
& &\int_a^b\frac{\left(a^{-1}qt,b^{-1}qt,ct;q\right)_{\infty}}{\left(dt,et,ft;q\right)_{\infty}}\,d_qt\nonumber\\
& &{}=(b-a)(1-q)\,\frac{\left(q,a^{-1}bq,ab^{-1}q,cd^{-1},ce^{-1},cf^{-1};q\right)_{\infty}}
{\left(ad,ae,af,bd,be,bf;q\right)_{\infty}},
\end{eqnarray}
provided that $c=abdef$. By taking the limit $f\rightarrow 0$, we obtain
\begin{equation}
\label{qint4}
\int_a^b\frac{\left(a^{-1}qt,b^{-1}qt;q\right)_{\infty}}{\left(dt,et;q\right)_{\infty}}\,d_qt
=(b-a)(1-q)\,\frac{\left(q,a^{-1}bq,ab^{-1}q,abde;q\right)_{\infty}}{\left(ad,ae,bd,be;q\right)_{\infty}}.
\end{equation}

\vspace{5mm}

\noindent
Limit cases of (\ref{qint4}) are
\begin{equation}
\label{qint5}
\int_a^{\infty}\frac{\left(a^{-1}qt;q\right)_{\infty}}{\left(dt,et;q\right)_{\infty}}\,d_qt
=(1-q)\,\frac{\left(q,a,a^{-1}q,ade,a^{-1}d^{-1}e^{-1}q;q\right)_{\infty}}
{\left(ad,ae,d,d^{-1}q,e,e^{-1}q;q\right)_{\infty}}
\end{equation}
and
\begin{eqnarray}
\label{qint6}
& &\int_{-\infty}^{\infty}\frac{1}{\left(dt,et;q\right)_{\infty}}\,d_qt\nonumber\\
& &{}=(1-q)\,\frac{\left(q,-q,-1,-de,-d^{-1}e^{-1}q;q\right)_{\infty}}
{\left(d,-d,d^{-1}q,-d^{-1}q,e,-e,e^{-1}q,-e^{-1}q;q\right)_{\infty}}.
\end{eqnarray}

\section{Shift operators and Rodrigues-type formulas}
\par\setcounter{equation}{0}
\label{shift operators}

We need some more differential and difference operators to formulate the
Rodrigues-type formulas. These operators can also be used to formulate the
second-order differential or difference equations but this is mostly avoided.
As usual, we will use the notation
$$f'(x)=\frac{d}{dx}f(x)=\frac{df}{dx}(x)=\frac{df(x)}{dx}.$$
Further we define
\begin{equation}
\label{DefDelta}
\Delta f(x)=f(x+1)-f(x),
\end{equation}
\begin{equation}
\label{DefNabla}
\nabla f(x)=f(x)-f(x-1)
\end{equation}
and
\begin{equation}
\label{delta-operator}
\delta f(x)=f(x+\textstyle\frac{1}{2}i)-f(x-\textstyle\frac{1}{2}i).
\end{equation}
The ordinary difference operator $\Delta$ given by (\ref{DefDelta}) is also a
special case of Hahn's $q$-operator defined in section~\ref{Hahnoperator}.

Note that (\ref{delta-operator}) implies that
$$\delta^2 f(x)=f(x+i)-f(x)-f(x)+f(x-i)=f(x+i)-2f(x)+f(x-i),$$
$$\delta x=x+\textstyle\frac{1}{2}i-(x-\textstyle\frac{1}{2}i)=i
\quad\textrm{and}\quad
\delta x^2=(x+\textstyle\frac{1}{2}i)^2-(x-\textstyle\frac{1}{2}i)^2=2ix.$$
Further we have for $\lambda(x):=x(x+\gamma+\delta+1)$
$$\Delta\lambda(x)=2x+\gamma+\delta+2\quad\textrm{and}\quad\nabla\lambda(x)=2x+\gamma+\delta.$$

In a similar way we have for $\mu(x):=q^{-x}+\gamma\delta q^{x+1}$
$$\Delta\mu(x)=q^{-x-1}(1-q)(1-\gamma\delta q^{2x+2})\quad\textrm{and}\quad
\nabla\mu(x)=q^{-x}(1-q)(1-\gamma\delta q^{2x})$$
and hence for $\lambda(x):=q^{-x}+cq^{x-N}$
$$\Delta\lambda(x)=q^{-x-1}(1-q)(1-cq^{2x-N+1})\quad\textrm{and}\quad
\nabla\lambda(x)=q^{-x}(1-q)(1-cq^{2x-N-1}).$$
Also note that
$$\Delta q^{-x}=q^{-x-1}(1-q)\quad\textrm{and}\quad\nabla q^{-x}=q^{-x}(1-q).$$

Finally, we define
\begin{equation}
\label{Dq-operator}
D_qf(x):=\frac{\delta_qf(x)}{\delta_qx}, \quad x=\cos\theta
\end{equation}
with
$$\delta_qf(\e^{i\theta})
=f(q^{\frac{1}{2}}\e^{i\theta})-f(q^{-\frac{1}{2}}\e^{i\theta}).$$
Here we have
$$\delta_qx=-\textstyle\frac{1}{2}q^{-\frac{1}{2}}(1-q)(\e^{i\theta}-\e^{-i\theta}),
\quad x=\cos\theta.$$

\end{document}
